{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This entire note book can be run just by run all cell\n",
    "\n",
    "If you need to input new dataset, please but it in the test_img folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'yolov9' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/SkalskiP/yolov9.git\n",
    "# %cd yolov9\n",
    "!pip install -q -r yolov9/requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect the brand of the image which include\n",
    "- Bia-Viet, \n",
    "- Heineken, \n",
    "- Laure, \n",
    "- Strong-bow, \n",
    "- Tiger, \n",
    "- Bivina"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output of the prediction will be in output_brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['weights/model_brand.pt'], source=test_img/, data=data.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=., name=output_brand, exist_ok=True, line_thickness=2, hide_labels=True, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ 1e33dbb Python-3.11.7 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "gelan-c summary: 467 layers, 25417128 parameters, 0 gradients, 102.5 GFLOPs\n",
      "image 1/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/Img_1.jpg: 480x640 22 Bia-Viets, 14 Heineken-brands, 50 Tiger-brands, 5 bivina-brands, 325.3ms\n",
      "image 2/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/img_2.jpg: 640x640 4 Heineken-brands, 30 bivina-brands, 523.2ms\n",
      "image 3/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/img_3.jpg: 480x640 9 Bia-Viets, 52 Heineken-brands, 3 Laure-brands, 58 Tiger-brands, 4 strongbows, 359.3ms\n",
      "image 4/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/img_4.jpg: 640x480 12 Bia-Viets, 16 Heineken-brands, 65 Tiger-brands, 349.5ms\n",
      "Speed: 0.4ms pre-process, 389.3ms inference, 2.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1moutput_brand\u001b[0m\n",
      "4 labels saved to output_brand/labels\n"
     ]
    }
   ],
   "source": [
    "!python yolov9/detect.py --weights weights/model_brand.pt --source test_img/ --line-thickness 2 --save-txt --data data.yaml --project . --name output_brand --exist-ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Bia-Viet: Red\n",
      "Heineken: Green\n",
      "Laure: Blue\n",
      "Strong-bow: Yellow\n",
      "Tiger: Magenta\n",
      "Bivina: Cyan\n",
      "strong-bow: Purple\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Define class names and colors\n",
    "with open(\"data_brand.yaml\", 'r') as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "class_names = data_yaml['names']\n",
    "colors = [\n",
    "    (255, 0, 0),    # Red\n",
    "    (0, 255, 0),    # Green\n",
    "    (0, 0, 255),    # Blue\n",
    "    (0, 255, 255),  # Yellow\n",
    "    (255, 0, 255),  # Magenta\n",
    "    (0, 255, 255),  # Cyan\n",
    "    (128, 0, 128)   # Purple\n",
    "]\n",
    "color_names = ['Red', 'Green', 'Blue', 'Yellow', 'Magenta', 'Cyan', 'Purple']\n",
    "\n",
    "# Extend colors if there are more classes\n",
    "if len(class_names) > len(colors):\n",
    "    colors = colors * (len(class_names) // len(colors) + 1)\n",
    "    color_names = color_names * (len(class_names) // len(color_names) + 1)\n",
    "\n",
    "# Print class colors\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {color_names[i]}\")\n",
    "\n",
    "# Directories\n",
    "image_dir = \"output_brand\"\n",
    "label_dir = \"output_brand/labels\"\n",
    "\n",
    "# Load the images\n",
    "image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "for image_filename in image_filenames:\n",
    "    img_path = os.path.join(image_dir, image_filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    dh, dw, _ = img.shape\n",
    "\n",
    "    # Scale text size based on image size\n",
    "    text_scale = 0.6 * (dw / 640)  # 0.6 is the base size for 640x640 image\n",
    "    text_thickness = int(2 * (dw / 640))  # Scale text thickness similarly\n",
    "\n",
    "    label_filename = image_filename.replace(\".jpg\", \".txt\").replace(\".jpeg\", \".txt\").replace(\".png\", \".txt\").replace(\".bmp\", \".txt\").replace(\".tiff\", \".txt\")\n",
    "    label_path = os.path.join(label_dir, label_filename)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"Label file {label_path} not found.\")\n",
    "        continue\n",
    "\n",
    "    with open(label_path, 'r') as fl:\n",
    "        data = fl.readlines()\n",
    "\n",
    "    for dt in data:\n",
    "        class_id, x, y, w, h = map(float, dt.split())\n",
    "\n",
    "        l = int((x - w / 2) * dw)\n",
    "        r = int((x + w / 2) * dw)\n",
    "        t = int((y - h / 2) * dh)\n",
    "        b = int((y + h / 2) * dh)\n",
    "        \n",
    "        l = max(0, l)\n",
    "        r = min(dw - 1, r)\n",
    "        t = max(0, t)\n",
    "        b = min(dh - 1, b)\n",
    "        # print(class_id)\n",
    "        color = colors[int(class_id) % 7]\n",
    "        cv2.rectangle(img, (l, t), (r, b), color, 2)\n",
    "        cv2.putText(img, class_names[int(class_id)% 7], (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, text_scale, color, text_thickness)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecte the image object which include\n",
    "- billboard\n",
    "- box \n",
    "- bucket, \n",
    "- crate, \n",
    "- fridge, \n",
    "- glass bottle, \n",
    "- glass cup, \n",
    "- person, \n",
    "- poster, \n",
    "- promotional display,\n",
    "- tin can,\n",
    "- umbrella"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['weights/model_object.pt'], source=test_img/, data=data.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=., name=output_object, exist_ok=True, line_thickness=2, hide_labels=True, hide_conf=True, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ 1e33dbb Python-3.11.7 torch-2.2.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "gelan-e summary: 930 layers, 58011316 parameters, 0 gradients, 190.9 GFLOPs\n",
      "image 1/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/Img_1.jpg: 480x640 1 billboard, 58 boxs, 5 persons, 1 poster, 1 tin can, 999.5ms\n",
      "image 2/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/img_2.jpg: 640x640 4 billboards, 55 boxs, 1 glass cup, 2 persons, 3 posters, 1 tin can, 1054.2ms\n",
      "image 3/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/img_3.jpg: 480x640 100 boxs, 1 crate, 819.0ms\n",
      "image 4/4 /Users/leviettung/Downloads/quick-commit/hackhcmc/test_img/img_4.jpg: 640x480 75 boxs, 23 crates, 1 tin can, 750.8ms\n",
      "Speed: 0.4ms pre-process, 905.9ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1moutput_object\u001b[0m\n",
      "4 labels saved to output_object/labels\n"
     ]
    }
   ],
   "source": [
    "!python yolov9/detect.py --weights weights/model_object.pt --source test_img/ --line-thickness 2 --save-txt --data data.yaml --project . --name output_object --exist-ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output of the prediction will be in output_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "billboard: (31, 119, 180)\n",
      "box: (174, 199, 232)\n",
      "bucket: (255, 187, 120)\n",
      "crate: (152, 223, 138)\n",
      "fridge: (255, 152, 150)\n",
      "glass bottle: (197, 176, 213)\n",
      "glass cup: (140, 86, 75)\n",
      "person: (227, 119, 194)\n",
      "poster: (127, 127, 127)\n",
      "promotional display: (188, 189, 34)\n",
      "tin can: (23, 190, 207)\n",
      "umbrella: (158, 218, 229)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define class names\n",
    "with open(\"data_object.yaml\", 'r') as f:\n",
    "    data_yaml = yaml.safe_load(f)\n",
    "\n",
    "class_names = data_yaml['names']\n",
    "\n",
    "# Generate 12 distinct colors using a colormap\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors = [cmap(i)[:3] for i in np.linspace(0, 1, 12)]\n",
    "colors = [(int(r*255), int(g*255), int(b*255)) for r, g, b in colors]\n",
    "\n",
    "# Print class colors\n",
    "for i, class_name in enumerate(class_names):\n",
    "    print(f\"{class_name}: {colors[i]}\")\n",
    "\n",
    "# Directories\n",
    "image_dir = \"output_object\"\n",
    "label_dir = \"output_object/labels\"\n",
    "\n",
    "# Load the images\n",
    "image_filenames = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "\n",
    "for image_filename in image_filenames:\n",
    "    img_path = os.path.join(image_dir, image_filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    dh, dw, _ = img.shape\n",
    "\n",
    "    label_filename = image_filename.replace(\".jpg\", \".txt\").replace(\".jpeg\", \".txt\").replace(\".png\", \".txt\").replace(\".bmp\", \".txt\").replace(\".tiff\", \".txt\")\n",
    "    label_path = os.path.join(label_dir, label_filename)\n",
    "\n",
    "    with open(label_path, 'r') as fl:\n",
    "        data = fl.readlines()\n",
    "\n",
    "    # Scale text size based on image size\n",
    "    text_scale = 0.6 * (min(dw, dh) / 640)  # 0.6 is the base size for 640x640 image\n",
    "    text_thickness = int(2 * (min(dw, dh) / 640))  # Scale text thickness similarly\n",
    "\n",
    "    for dt in data:\n",
    "        class_id, x, y, w, h = map(float, dt.split())\n",
    "\n",
    "        l = int((x - w / 2) * dw)\n",
    "        r = int((x + w / 2) * dw)\n",
    "        t = int((y - h / 2) * dh)\n",
    "        b = int((y + h / 2) * dh)\n",
    "        \n",
    "        l = max(0, l)\n",
    "        r = min(dw - 1, r)\n",
    "        t = max(0, t)\n",
    "        b = min(dh - 1, b)\n",
    "\n",
    "        color = colors[int(class_id)]\n",
    "        cv2.rectangle(img, (l, t), (r, b), color, 2)\n",
    "        cv2.putText(img, class_names[int(class_id)], (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, text_scale, color, text_thickness)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the object and the brand by performing intersection over union\n",
    "\n",
    "We will have a total of 7 ( classes of brands ) * 12 (classes of object) = 84 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output of the prediction will be in output_overlapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n",
      "Combined Class 0: Object 'billboard', Label 'Bia-Viet', Color (57, 59, 121)\n",
      "Combined Class 1: Object 'billboard', Label 'Heineken', Color (82, 84, 163)\n",
      "Combined Class 2: Object 'billboard', Label 'Laure', Color (107, 110, 207)\n",
      "Combined Class 3: Object 'billboard', Label 'Strong-bow', Color (156, 158, 222)\n",
      "Combined Class 4: Object 'billboard', Label 'Tiger', Color (99, 121, 57)\n",
      "Combined Class 5: Object 'billboard', Label 'Bivina', Color (140, 162, 82)\n",
      "Combined Class 6: Object 'billboard', Label 'strong-bow', Color (181, 207, 107)\n",
      "Combined Class 7: Object 'box', Label 'Bia-Viet', Color (206, 219, 156)\n",
      "Combined Class 8: Object 'box', Label 'Heineken', Color (140, 109, 49)\n",
      "Combined Class 9: Object 'box', Label 'Laure', Color (189, 158, 57)\n",
      "Combined Class 10: Object 'box', Label 'Strong-bow', Color (231, 186, 82)\n",
      "Combined Class 11: Object 'box', Label 'Tiger', Color (231, 203, 148)\n",
      "Combined Class 12: Object 'box', Label 'Bivina', Color (132, 60, 57)\n",
      "Combined Class 13: Object 'box', Label 'strong-bow', Color (173, 73, 74)\n",
      "Combined Class 14: Object 'bucket', Label 'Bia-Viet', Color (214, 97, 107)\n",
      "Combined Class 15: Object 'bucket', Label 'Heineken', Color (231, 150, 156)\n",
      "Combined Class 16: Object 'bucket', Label 'Laure', Color (123, 65, 115)\n",
      "Combined Class 17: Object 'bucket', Label 'Strong-bow', Color (165, 81, 148)\n",
      "Combined Class 18: Object 'bucket', Label 'Tiger', Color (206, 109, 189)\n",
      "Combined Class 19: Object 'bucket', Label 'Bivina', Color (222, 158, 214)\n",
      "Combined Class 20: Object 'bucket', Label 'strong-bow', Color (57, 59, 121)\n",
      "Combined Class 21: Object 'crate', Label 'Bia-Viet', Color (82, 84, 163)\n",
      "Combined Class 22: Object 'crate', Label 'Heineken', Color (107, 110, 207)\n",
      "Combined Class 23: Object 'crate', Label 'Laure', Color (156, 158, 222)\n",
      "Combined Class 24: Object 'crate', Label 'Strong-bow', Color (99, 121, 57)\n",
      "Combined Class 25: Object 'crate', Label 'Tiger', Color (140, 162, 82)\n",
      "Combined Class 26: Object 'crate', Label 'Bivina', Color (181, 207, 107)\n",
      "Combined Class 27: Object 'crate', Label 'strong-bow', Color (206, 219, 156)\n",
      "Combined Class 28: Object 'fridge', Label 'Bia-Viet', Color (140, 109, 49)\n",
      "Combined Class 29: Object 'fridge', Label 'Heineken', Color (189, 158, 57)\n",
      "Combined Class 30: Object 'fridge', Label 'Laure', Color (231, 186, 82)\n",
      "Combined Class 31: Object 'fridge', Label 'Strong-bow', Color (231, 203, 148)\n",
      "Combined Class 32: Object 'fridge', Label 'Tiger', Color (132, 60, 57)\n",
      "Combined Class 33: Object 'fridge', Label 'Bivina', Color (173, 73, 74)\n",
      "Combined Class 34: Object 'fridge', Label 'strong-bow', Color (214, 97, 107)\n",
      "Combined Class 35: Object 'glass bottle', Label 'Bia-Viet', Color (231, 150, 156)\n",
      "Combined Class 36: Object 'glass bottle', Label 'Heineken', Color (123, 65, 115)\n",
      "Combined Class 37: Object 'glass bottle', Label 'Laure', Color (165, 81, 148)\n",
      "Combined Class 38: Object 'glass bottle', Label 'Strong-bow', Color (206, 109, 189)\n",
      "Combined Class 39: Object 'glass bottle', Label 'Tiger', Color (222, 158, 214)\n",
      "Combined Class 40: Object 'glass bottle', Label 'Bivina', Color (57, 59, 121)\n",
      "Combined Class 41: Object 'glass bottle', Label 'strong-bow', Color (82, 84, 163)\n",
      "Combined Class 42: Object 'glass cup', Label 'Bia-Viet', Color (107, 110, 207)\n",
      "Combined Class 43: Object 'glass cup', Label 'Heineken', Color (156, 158, 222)\n",
      "Combined Class 44: Object 'glass cup', Label 'Laure', Color (99, 121, 57)\n",
      "Combined Class 45: Object 'glass cup', Label 'Strong-bow', Color (140, 162, 82)\n",
      "Combined Class 46: Object 'glass cup', Label 'Tiger', Color (181, 207, 107)\n",
      "Combined Class 47: Object 'glass cup', Label 'Bivina', Color (206, 219, 156)\n",
      "Combined Class 48: Object 'glass cup', Label 'strong-bow', Color (140, 109, 49)\n",
      "Combined Class 49: Object 'person', Label 'Bia-Viet', Color (189, 158, 57)\n",
      "Combined Class 50: Object 'person', Label 'Heineken', Color (231, 186, 82)\n",
      "Combined Class 51: Object 'person', Label 'Laure', Color (231, 203, 148)\n",
      "Combined Class 52: Object 'person', Label 'Strong-bow', Color (132, 60, 57)\n",
      "Combined Class 53: Object 'person', Label 'Tiger', Color (173, 73, 74)\n",
      "Combined Class 54: Object 'person', Label 'Bivina', Color (214, 97, 107)\n",
      "Combined Class 55: Object 'person', Label 'strong-bow', Color (231, 150, 156)\n",
      "Combined Class 56: Object 'poster', Label 'Bia-Viet', Color (123, 65, 115)\n",
      "Combined Class 57: Object 'poster', Label 'Heineken', Color (165, 81, 148)\n",
      "Combined Class 58: Object 'poster', Label 'Laure', Color (206, 109, 189)\n",
      "Combined Class 59: Object 'poster', Label 'Strong-bow', Color (222, 158, 214)\n",
      "Combined Class 60: Object 'poster', Label 'Tiger', Color (57, 59, 121)\n",
      "Combined Class 61: Object 'poster', Label 'Bivina', Color (82, 84, 163)\n",
      "Combined Class 62: Object 'poster', Label 'strong-bow', Color (107, 110, 207)\n",
      "Combined Class 63: Object 'promotional display', Label 'Bia-Viet', Color (156, 158, 222)\n",
      "Combined Class 64: Object 'promotional display', Label 'Heineken', Color (99, 121, 57)\n",
      "Combined Class 65: Object 'promotional display', Label 'Laure', Color (140, 162, 82)\n",
      "Combined Class 66: Object 'promotional display', Label 'Strong-bow', Color (181, 207, 107)\n",
      "Combined Class 67: Object 'promotional display', Label 'Tiger', Color (206, 219, 156)\n",
      "Combined Class 68: Object 'promotional display', Label 'Bivina', Color (140, 109, 49)\n",
      "Combined Class 69: Object 'promotional display', Label 'strong-bow', Color (189, 158, 57)\n",
      "Combined Class 70: Object 'tin can', Label 'Bia-Viet', Color (231, 186, 82)\n",
      "Combined Class 71: Object 'tin can', Label 'Heineken', Color (231, 203, 148)\n",
      "Combined Class 72: Object 'tin can', Label 'Laure', Color (132, 60, 57)\n",
      "Combined Class 73: Object 'tin can', Label 'Strong-bow', Color (173, 73, 74)\n",
      "Combined Class 74: Object 'tin can', Label 'Tiger', Color (214, 97, 107)\n",
      "Combined Class 75: Object 'tin can', Label 'Bivina', Color (231, 150, 156)\n",
      "Combined Class 76: Object 'tin can', Label 'strong-bow', Color (123, 65, 115)\n",
      "Combined Class 77: Object 'umbrella', Label 'Bia-Viet', Color (165, 81, 148)\n",
      "Combined Class 78: Object 'umbrella', Label 'Heineken', Color (206, 109, 189)\n",
      "Combined Class 79: Object 'umbrella', Label 'Laure', Color (222, 158, 214)\n",
      "Combined Class 80: Object 'umbrella', Label 'Strong-bow', Color (57, 59, 121)\n",
      "Combined Class 81: Object 'umbrella', Label 'Tiger', Color (82, 84, 163)\n",
      "Combined Class 82: Object 'umbrella', Label 'Bivina', Color (107, 110, 207)\n",
      "Combined Class 83: Object 'umbrella', Label 'strong-bow', Color (156, 158, 222)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%matplotlib\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Helper function to compute IoU\n",
    "def compute_iou(box1, box2):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x1g, y1g, x2g, y2g = box2\n",
    "\n",
    "    xi1 = max(x1, x1g)\n",
    "    yi1 = max(y1, y1g)\n",
    "    xi2 = min(x2, x2g)\n",
    "    yi2 = min(y2, y2g)\n",
    "    inter_area = max(0, xi2 - xi1) * max(0, yi2 - yi1)\n",
    "\n",
    "    box1_area = (x2 - x1) * (y2 - y1)\n",
    "    box2_area = (x2g - x1g) * (y2g - y1g)\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n",
    "\n",
    "# Generate 84 distinct darker colors\n",
    "def generate_darker_colors(n):\n",
    "    cmap = plt.get_cmap('tab20b')\n",
    "    colors = [cmap(i % cmap.N)[:3] for i in range(n)]\n",
    "    dark_factor = 1.0  # Scaling factor to make colors darker\n",
    "    colors = [(int(r*dark_factor*255), int(g*dark_factor*255), int(b*dark_factor*255)) for r, g, b in colors]\n",
    "    return colors\n",
    "\n",
    "# Generate colors for 84 classes\n",
    "combined_colors = generate_darker_colors(84)\n",
    "\n",
    "# Load class names\n",
    "with open(\"data_brand.yaml\", 'r') as f:\n",
    "    data_brand_yaml = yaml.safe_load(f)\n",
    "label_class_names = data_brand_yaml['names']\n",
    "\n",
    "with open(\"data_object.yaml\", 'r') as f:\n",
    "    data_object_yaml = yaml.safe_load(f)\n",
    "object_class_names = data_object_yaml['names']\n",
    "\n",
    "# Print class colors\n",
    "new_combine_class_name = []\n",
    "for i, (obj_class_name, label_class_name) in enumerate(\n",
    "        [(obj, lbl) for obj in object_class_names for lbl in label_class_names]):\n",
    "    print(f\"Combined Class {i}: Object '{obj_class_name}', Label '{label_class_name}', Color {combined_colors[i]}\")\n",
    "    new_combine_class_name.append(label_class_name + '.' + obj_class_name)\n",
    "\n",
    "# Directories for input and output\n",
    "object_dir = \"output_object/labels\"\n",
    "label_dir = \"output_brand/labels\"\n",
    "output_dir = \"output_overlapped\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to get bounding boxes\n",
    "def get_bounding_boxes(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    bboxes = []\n",
    "    for dt in data:\n",
    "        class_id, x, y, w, h = map(float, dt.split())\n",
    "        bboxes.append((int(class_id), x, y, w, h))\n",
    "    return bboxes\n",
    "\n",
    "# Function to check if a file is an image\n",
    "def is_image_file(filename):\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']\n",
    "    return any(filename.lower().endswith(ext) for ext in image_extensions)\n",
    "\n",
    "# Load the images\n",
    "image_filenames = [f for f in os.listdir(\"test_img\") if is_image_file(f)]\n",
    "for image_filename in image_filenames:\n",
    "    img_path = os.path.join(\"test_img\", image_filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    dh, dw, _ = img.shape\n",
    "\n",
    "    # Calculate scale factor for font size\n",
    "    reference_height = 640\n",
    "    scale_factor = dh / reference_height\n",
    "    font_size = 0.6 * scale_factor\n",
    "\n",
    "    # Load object and label bounding boxes\n",
    "    object_bboxes = get_bounding_boxes(os.path.join(object_dir, image_filename.replace(\".jpg\", \".txt\")))\n",
    "    label_bboxes = get_bounding_boxes(os.path.join(label_dir, image_filename.replace(\".jpg\", \".txt\")))\n",
    "\n",
    "    # Sort object bounding boxes by size (area)\n",
    "    object_bboxes.sort(key=lambda bbox: bbox[3] * bbox[4])  # Sorting by w * h\n",
    "\n",
    "    matched_labels = []\n",
    "\n",
    "    for obj_class_id, x, y, w, h in object_bboxes:\n",
    "        l = int((x - w / 2) * dw)\n",
    "        r = int((x + w / 2) * dw)\n",
    "        t = int((y - h / 2) * dh)\n",
    "        b = int((y + h / 2) * dh)\n",
    "\n",
    "        l = max(0, l)\n",
    "        r = min(dw - 1, r)\n",
    "        t = max(0, t)\n",
    "        b = min(dh - 1, b)\n",
    "\n",
    "        obj_box = (l, t, r, b)\n",
    "        best_iou = 0\n",
    "        best_label = None\n",
    "\n",
    "        for label_class_id, lx, ly, lw, lh in label_bboxes:\n",
    "            ll = int((lx - lw / 2) * dw)\n",
    "            lr = int((lx + lw / 2) * dw)\n",
    "            lt = int((ly - lh / 2) * dh)\n",
    "            lb = int((ly + lh / 2) * dh)\n",
    "\n",
    "            ll = max(0, ll)\n",
    "            lr = min(dw - 1, lr)\n",
    "            lt = max(0, lt)\n",
    "            lb = min(dh - 1, lb)\n",
    "\n",
    "            label_box = (ll, lt, lr, lb)\n",
    "            iou = compute_iou(obj_box, label_box)\n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_label = (label_class_id, lx, ly, lw, lh)\n",
    "\n",
    "        if best_label:\n",
    "            label_class_id, lx, ly, lw, lh = best_label\n",
    "            matched_labels.append((obj_class_id, label_class_id, x, y, w, h))  # Store object x, y, w, h\n",
    "            label_bboxes.remove(best_label)\n",
    "\n",
    "    # Save matched results\n",
    "    output_txt_path = os.path.join(output_dir, image_filename.replace(\".jpg\", \".txt\"))\n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        for obj_class_id, label_class_id, ox, oy, ow, oh in matched_labels:\n",
    "            combined_class_id = obj_class_id * len(label_class_names) + label_class_id\n",
    "            f.write(f\"{combined_class_id} {ox} {oy} {ow} {oh}\\n\")\n",
    "\n",
    "    # Visualize and save image\n",
    "    for obj_class_id, label_class_id, ox, oy, ow, oh in matched_labels:\n",
    "        l = int((ox - ow / 2) * dw)\n",
    "        r = int((ox + ow / 2) * dw)\n",
    "        t = int((oy - oh / 2) * dh)\n",
    "        b = int((oy + oh / 2) * dh)\n",
    "\n",
    "        l = max(0, l)\n",
    "        r = min(dw - 1, r)\n",
    "        t = max(0, t)\n",
    "        b = min(dh - 1, b)\n",
    "\n",
    "        combined_class_id = obj_class_id * len(label_class_names) + label_class_id\n",
    "        color = combined_colors[combined_class_id]\n",
    "        cv2.rectangle(img, (l, t), (r, b), color, 2)\n",
    "        cv2.putText(img, new_combine_class_name[combined_class_id], (l, t - 10), cv2.FONT_HERSHEY_SIMPLEX, font_size, color, 2)\n",
    "\n",
    "    output_img_path = os.path.join(output_dir, image_filename)\n",
    "    cv2.imwrite(output_img_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "output_dir = \"output_overlapped\"\n",
    "\n",
    "# Get all image filenames in the directory\n",
    "image_filenames = [f for f in os.listdir(output_dir) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "# Plot each image\n",
    "for image_filename in image_filenames:\n",
    "    img_path = os.path.join(output_dir, image_filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image {img_path}\")\n",
    "        continue\n",
    "\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))  # Adjust the figure size as needed\n",
    "    plt.imshow(img)\n",
    "    plt.title(image_filename)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
